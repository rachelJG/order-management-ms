services:
  order-management-ms:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "${SERVER_PORT}:${SERVER_PORT}"
    environment:
      - GIN_MODE=${GIN_MODE}
      - ENVIRONMENT=${ENVIRONMENT}
      - SERVER_PORT=${SERVER_PORT}
      # MongoDB
      - MONGO_PORT=27017  
      - MONGO_HOST=mongodb
      - MONGO_USERNAME=${MONGO_USERNAME}
      - MONGO_PASSWORD=${MONGO_PASSWORD}
      # Redis
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_DB=${REDIS_DB}
      - REDIS_PORT=6379
      - REDIS_HOST=redis
      # Kafka
      - KAFKA_BROKERS=kafka:29092
      - KAFKA_GROUP_ID=${KAFKA_GROUP_ID}
      - KAFKA_TOPIC=${KAFKA_TOPIC}
    env_file:
      - .env
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - order-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "http://localhost:${SERVER_PORT}/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  mongodb:
    container_name: mongodb
    image: mongo:latest
    hostname: "${MONGO_HOST:-mongodb}"
    ports:
      - "${MONGO_PORT:-27019}:27017"
    volumes:
      - mongodb_data:/data/db
    environment:
      - MONGO_DATABASE=${MONGO_DATABASE:-orderdb}
      - MONGO_USERNAME=${MONGO_USERNAME:-admin}
      - MONGO_PASSWORD=${MONGO_PASSWORD:-1qaz2wsx}
    command: ["--quiet", "--logpath=/dev/null"]
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - order-network
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 5s
      retries: 5
      
  redis:
    image: redis:alpine
    container_name: redis
    hostname: "${REDIS_HOST:-redis}"
    ports:
      - "${REDIS_PORT:-6380}:6379"
    volumes:
      - redis_data:/data
    command: redis-server --requirepass ${REDIS_PASSWORD} --bind 0.0.0.0
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    networks:
      - order-network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=WARN,kafka.producer.async.DefaultEventHandler=WARN,state.change.logger=WARN"
      KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 30s
      timeout: 10s
      start_period: 40s
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - order-network

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: echo srvr | nc localhost 2181 || exit 1
      interval: 10s
      timeout: 5s
      retries: 10
    ports:
      - "2181:2181"
    networks:
      - order-network

networks:
  order-network:
    driver: bridge

volumes:
  mongodb_data:
  redis_data:
